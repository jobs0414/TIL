{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### . Pandas 학습 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 데이터 분석을 위한 모듈 \n",
    "> 주요 Library \n",
    "> DataFrame \n",
    "    -Series 구성 \n",
    "\n",
    "> Serires \n",
    "    - column 구조의 데이터 구조 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas- 사용 위한 필수 설정 \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기초 익히기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시리즈 생성해서 DataFrame 만들기 연습 \n",
    "# 결측치 적용 \n",
    "s = pd.Series([1,2,3,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    3.0\n",
       "3    NaN\n",
       "4    4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.nan으로 데이터 셋에 결측치 반영 가능, 단  \n",
    "# 이 시리즈의 데이터들은 float 값으로 간주 \n",
    "s = pd.Series([1,2,3,np.nan,4])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame 이 없어서 info() 사용 안된다. \n",
    "#s.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1,2,3,4])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#특정 일자를 기준으로 자동으로 날짜 증가 \n",
    "dates = pd.date_range('20180812',periods=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-08-12', '2018-08-13', '2018-08-14', '2018-08-15',\n",
       "               '2018-08-16', '2018-08-17'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(6,4),\n",
    "                  index=dates,\n",
    "                  columns=['A','B','C','D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-12</th>\n",
       "      <td>0.266205</td>\n",
       "      <td>-0.137265</td>\n",
       "      <td>-1.531417</td>\n",
       "      <td>-0.309110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-13</th>\n",
       "      <td>1.148619</td>\n",
       "      <td>1.567388</td>\n",
       "      <td>1.037397</td>\n",
       "      <td>-0.335607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-14</th>\n",
       "      <td>-0.406667</td>\n",
       "      <td>0.422507</td>\n",
       "      <td>1.185946</td>\n",
       "      <td>0.732000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15</th>\n",
       "      <td>2.229930</td>\n",
       "      <td>-0.119276</td>\n",
       "      <td>-1.178426</td>\n",
       "      <td>-0.220651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-16</th>\n",
       "      <td>-1.066663</td>\n",
       "      <td>0.336374</td>\n",
       "      <td>0.304974</td>\n",
       "      <td>0.091319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-17</th>\n",
       "      <td>0.353565</td>\n",
       "      <td>-1.090432</td>\n",
       "      <td>-1.819470</td>\n",
       "      <td>-1.312454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2018-08-12  0.266205 -0.137265 -1.531417 -0.309110\n",
       "2018-08-13  1.148619  1.567388  1.037397 -0.335607\n",
       "2018-08-14 -0.406667  0.422507  1.185946  0.732000\n",
       "2018-08-15  2.229930 -0.119276 -1.178426 -0.220651\n",
       "2018-08-16 -1.066663  0.336374  0.304974  0.091319\n",
       "2018-08-17  0.353565 -1.090432 -1.819470 -1.312454"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame 구조 파악하는 중요한 함수 \n",
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()   #wow 수학 + 통계 통계 수치가 한번에 보이네? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # oracle db 시에 정렬 옵션 -desc[내림차순], asc[오름차순]\n",
    "    \n",
    "    \n",
    "  # B컬럼을 기준으로 \n",
    "df.sort_values(by='B',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'A' 컬럼을 기준으로 내림차순 정렬 \n",
    "df.sort_values(by='A',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#컬럼명으로 해당 컬럼값들만 도출, 모든 row 다 검색 \n",
    "df['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모든 컬럼의 0행~(3-1)행까지 데이터가 도출 \n",
    "\n",
    "df[0:3]  #해당하는 컬럼 값만. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2018-08-13':'2018-08-15'] #특정 인덱스 값 찾아서 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loc() : iloc ()\n",
    "df.loc [:,['A','B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#오류 컬럼명 처럼 index는 list 처리 불가 \n",
    "#df.loc[['20180814','20180815'],['A','B']]\n",
    "\n",
    "#index 는 : 을 기준으로 작성(범위)\n",
    "df.loc['20180815':'20180817',['A','B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loc \n",
    "    >-는 데이터를 슬라이싱 하는 문법으로 처리 \n",
    "     -loc[index,columns] <br> \n",
    "        : index는 : 즉 범위 설정 문법 <br> \n",
    "        : columns는 list 형태로 처리 가능 <br>\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iloc \n",
    "> loc 함수와 달리 행과 열의 번호를 이용해서 데이터 활용 <br> \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2] #3번쨰 열 a,b,c,d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#? iloc[3] 과 동일한 결과를 loc로 처리 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['20180815',['A','B','C','D']]\n",
    "#df.loc['20180815',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Art  요렇게 해도 된다. \n",
    "df.loc['20180815',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[1,2,4],[0,2]]  #1행,2행,4행 컬럼0,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#조건식을 반영해서 유효한 데이터 도출 \n",
    "df[df.A>0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 존재하는 DataFrame의 구조 및 모든 데이터 복사 붙여넣기\n",
    "#혹여 sql문장에서도 이미 존재하는 table의 복제본 table 생성 가능 \n",
    "#dept table의 복제본인 dept2 table \n",
    "#create table dept2 as select * from dept; \n",
    "df2=df.copy() \n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2의 구조에 새로운 컬럼 추가해 보기 \n",
    "# numpy의 nan 속성으로 결측치 반영 \n",
    "df2['E']=[1,2,3,4,np.nan,6] #np.nan 결측치 \n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 열에 E열에 속한 데이터 존재 여부 확인 함수  \n",
    "# 함수-isin()\n",
    "df2['E'].isin([1,3,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda - 람다 함수, 익명 함수, 수식으로 만 구성된 함수 \n",
    "# 로직 - 모든 컬럼값의 최대, 최소값 빼기한 결과치 \n",
    "# x에는 몇건의 데이터값 ? \n",
    "df.apply(lambda x : x.max() - x.min())\n",
    "\n",
    "#lambda 함수가 몇번 호출되는지 단순 확인 \n",
    "df.apply(lambda x : print(x)) # 파고들어서 확인 \n",
    "\n",
    "# 혜영 질문에 따른 고민 - Series 객체 타입 개수 확인 로직 \n",
    "# -함축된 표현만의 언어 - 스칼라 \n",
    "df.apply(lambda x : print(type(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미 존재하는 파일의 내용으로 DataFrame 생성하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# friends.csv 파일로 DataFrame 객체 생성 \n",
    "df = pd.read_csv('dataSet/friends.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이름만 출력 \n",
    "df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['이름']   #df.이름   된다. \n",
    "df['hobby']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# friendsTab.txt 파일로 DataFrame 객체 생성하기 \n",
    "# read_csv(), 구분자는 tab(\\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataSet/friendsTab.txt',delimiter='\\t')\n",
    "#df['이름'] 에러 \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#컬럼명 추가 \n",
    "\n",
    "#컬럼의 속성명 없이 데이터로만 구성된 file은 고려사항이 있음 \n",
    "\n",
    "#1라인 데이터가 heade 정보처럼 사용됨 \n",
    "df=pd.read_csv('dataSet/friendsNoHead.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('dataSet/friendsNoHead.csv',header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#컬럼명 추가 및 편집 \n",
    "df.columns=['name','age','job','hobby']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('dataSet/friendsNoHead.csv',header=None,\n",
    "              names=['name','age','job','hobby'])\n",
    "df   #d=컬럼명 반영과 동시에 DataFrame 객체 생성하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딕셔너리로 DataFrame 생성 \n",
    "# 기본적으론 선언된 컬럼 순서 보장을 안 함 \n",
    "# 가공 또는 OrderedDice 모듈 사용 \n",
    "friend_dict_list = [{'name': '신동엽', 'age': 20, 'job': '연예인', 'hobby':'music'},\n",
    "                     {'name': '유재석', 'age': 41, 'job': '교수', 'hobby':'art'},\n",
    "                     {'name': '김새롬', 'age': 18, 'job': '학생', 'hobby':'study'},\n",
    "                     {'name': '이영자', 'age' : 45, 'job': '상담사', 'hobby' : 'talk'},\n",
    "                     {'name' :  '강호동', 'age' : 38, 'job' : '연예인', 'hobby' : 'talk'}]\n",
    "\n",
    "df = pd.DataFrame(friend_dict_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 순서 설정하기 //지정하기\n",
    "df = df[['name','age','job']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트로 데이터 프레임 생성하기  리스트 형태!\n",
    "\n",
    "friends = [['신동엽',20,'연예인','music'], \n",
    "           ['유재석',41,'교수','art'], \n",
    "           ['김새롬',18,'학생','study'], \n",
    "           ['이영자',45,'상담사','talk'], \n",
    "           ['강호동',38,'연예인','talk']]\n",
    "\n",
    "df = pd.DataFrame.from_records(friends) \n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['name','age','job','hobby']\n",
    "df  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.job=='강호동'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가공된 DataFrame을 csv로 생성하기   아하!~!\n",
    "# csv or txt 등의 확장자 자유롭게 생성, 자동으로 index가 int로 반영\n",
    "# index 속성은 기본이 True\n",
    "\n",
    "df.to_csv('dataSet/f1_out.csv',index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop(삭제)\n",
    "# DB table- drop table table명 , drop sequence sequence명, ...\n",
    "# pandas의 drop은 특정 컬럼 또는 행 삭제가 가능. \n",
    "# drop() - axis가 생략된 경우 axis=0 즉 row 축 의미 \n",
    "\n",
    "df.drop(4) \n",
    "df.drop(2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(3,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql 문장의 like 연산자 \n",
    "#S로 시작, 단 두 음절로 되어 있는 데이터만 검색 \n",
    "#select * from tab명 where like ename like 'S_'\n",
    "#S로 시작, 단 두 음절 개수와 무관 \n",
    "    # # select * from tab명 where ename like 'S%'\n",
    "    \n",
    "#컬럼명에 a가 포함된 컬럼만 검색 \n",
    "df.filter(like='a',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#? n으로 시작하는 컬럼의 데이터 검색 \n",
    "# filter 의 axis default 는 1 (컬럼)\n",
    "df.filter(regex='^n', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b로 끝나는 job의 컬럼 데이터 검색 \n",
    "#$ 을 쓰면 \n",
    "df.filter(regex='b$', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#? 0, 3번쨰 row 데이터 삭제 \n",
    "df.drop(['job','name'] , axis=1)\n",
    "#[] 쓰고 삭제하면 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 =df.drop(df.index[[0,3]])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_dict_list = [{'name': '신동엽', 'age': 20, 'job': '연예인', 'hobby':'music'},\n",
    "                     {'name': '유재석', 'age': 41, 'job': '교수', 'hobby':'art'},\n",
    "                     {'name': '김새롬', 'age': 18, 'job': '학생', 'hobby':'study'},\n",
    "                     {'name': '이영자', 'age' : 45, 'job': '상담사', 'hobby' : 'talk'},\n",
    "                     {'name' :  '강호동', 'age' : 38, 'job' : '연예인', 'hobby' : 'talk'}]\n",
    "\n",
    "df = pd.DataFrame(friend_dict_list)\n",
    "df.columns['name','age','job','hobby']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#? salary 컬럼 추가, 단 모든 데이터 값은 0 \n",
    "df['salary']=[0,0,0,0,0] #내가 한 방법  \n",
    "#만약에 행이 100개라면? \n",
    "df['salary']=0 #쌤 답 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy를 이용해서 학생일 경우엔 no, 학생이 아닐 경우엔 yes \n",
    "# 전통 3항 연산자 - 조건식? 조건식이 true: 조건식이 false\n",
    "df['salary']= np.where(df['job'] != '학생','yes','no')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복 데이터 처리 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "friend_dict_list = [{'name': '신동엽', 'age': 20, 'job': '연예인', 'hobby':'music'},\n",
    "                     {'name': '유재석', 'age': 41, 'job': '교수', 'hobby':'art'},\n",
    "                     {'name': '김새롬', 'age': 18, 'job': '학생', 'hobby':'study'},\n",
    "                     {'name': '이영자', 'age' : 45, 'job': '상담사', 'hobby' : 'talk'},\n",
    "                     {'name' :  '강호동', 'age' : 38, 'job' : '연예인', 'hobby' : 'talk'},\n",
    "                    {'name': '신동엽', 'age': 20, 'job': '연예인', 'hobby':'music'} ]\n",
    "\n",
    "df = pd.DataFrame(friend_dict_list)\n",
    "df = df[['name', 'age', 'job', 'hobby']]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated() #어떤 게 중복인지를 알려줌. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼명으로 중복 데이터 삭제 하기 \n",
    "friend_dict_list = [{'name': '신동엽', 'age': 20, 'job': '연예인', 'hobby':'music'},\n",
    "                     {'name': '유재석', 'age': 41, 'job': '교수', 'hobby':'art'},\n",
    "                     {'name': '김새롬', 'age': 18, 'job': '학생', 'hobby':'study'},\n",
    "                     {'name': '이영자', 'age' : 45, 'job': '상담사', 'hobby' : 'talk'},\n",
    "                     {'name' :  '강호동', 'age' : 38, 'job' : '연예인', 'hobby' : 'talk'},\n",
    "                    {'name': '신동엽', 'age': 20, 'job': '연예인', 'hobby':'music'} ]\n",
    "\n",
    "df = pd.DataFrame(friend_dict_list)\n",
    "df = df[['name', 'age', 'job', 'hobby']]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(['name'], keep='first') # keep 숫자는 안되고 first last "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결측치 처리 하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_dict_list = [{'name': '신동엽', 'age': 20, 'job': '연예인', 'hobby':'music'},\n",
    "                     {'name': '유재석', 'age': 41, 'job': '교수', 'hobby':'art'},\n",
    "                     {'name': '김새롬', 'age': 18, 'job': '학생', 'hobby':'study'},\n",
    "                     {'name': '이영자', 'age' : 45, 'job': '상담사', 'hobby' : 'talk'},\n",
    "                     {'name' :  '강호동', 'age' : 38, 'job' : '연예인', 'hobby' : 'talk'},\n",
    "                    {'name': '신동엽', 'age': None, 'job': '연예인', 'hobby':'music'} ]\n",
    "\n",
    "df = pd.DataFrame(friend_dict_list)\n",
    "df=df[['name', 'age', 'job', 'hobby']]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#null 또는 Nan 값을 변경하기 \n",
    "#fillna() : na값을 찾아서 0으로 채우자 \n",
    "\n",
    "tmp = df \n",
    "tmp['age'] = tmp['age'].fillna(0)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치를 가설 검증 처럼 동일한 직업을 갖은 사람들의 평균값으로 대체 \n",
    "'''\n",
    "고려사항 - job을 직업군 별로 그룹화 - group\n",
    "- 평균 구하기 - median\n",
    "- 이미 존재하는 DataFrame의 결측치값 변경하기 - transform  \n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "friend_dict_list = [{'name': '신동엽', 'age': 20, 'job': '연예인', 'hobby':'music'},\n",
    "                     {'name': '유재석', 'age': 41, 'job': '교수', 'hobby':'art'},\n",
    "                     {'name': '김새롬', 'age': 18, 'job': '학생', 'hobby':'study'},\n",
    "                     {'name': '이영자', 'age' : 45, 'job': '상담사', 'hobby' : 'talk'},\n",
    "                     {'name' :  '강호동', 'age' : 38, 'job' : '연예인', 'hobby' : 'talk'},\n",
    "                    {'name': '신동엽', 'age': None, 'job': '연예인', 'hobby':'music'} ]\n",
    "\n",
    "df = pd.DataFrame(friend_dict_list)\n",
    "df=df[['name', 'age', 'job', 'hobby']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].fillna(df.groupby('job')['age'].transform('median'),\n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중복 데이터 관련된 unique 처리 기술 학습 \n",
    "> 컬럼에 여러값들이 있을 때 중복 없이 어떤 데이터들이 있는지 \n",
    "확인하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "고려사항 - job을 직업군 별로 그룹화 - group\n",
    "- 평균 구하기 - median\n",
    "- 이미 존재하는 DataFrame의 결측치값 변경하기 - transform  \n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "friend_dict_list = [{'name': '신동엽', 'age': 20, 'job': '연예인', 'hobby':'music'},\n",
    "                     {'name': '유재석', 'age': 41, 'job': '교수', 'hobby':'art'},\n",
    "                     {'name': '김새롬', 'age': 18, 'job': '학생', 'hobby':'study'},\n",
    "                     {'name': '이영자', 'age' : 45, 'job': '상담사', 'hobby' : 'talk'},\n",
    "                     {'name' :  '강호동', 'age' : 38, 'job' : '연예인', 'hobby' : 'talk'},\n",
    "                    {'name': '신동엽', 'age': None, 'job': '연예인', 'hobby':'music'} ]\n",
    "\n",
    "df = pd.DataFrame(friend_dict_list)\n",
    "df=df[['name', 'age', 'job', 'hobby']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oracle DB의 emp table의 job 검색, 중복불허 \n",
    "# select distinct job from emp; \n",
    "\n",
    "\n",
    "print(df.job.unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.job.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 두 개의 row 기준으로 DataFrame 병합하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l1 = [{'name': '이효리', 'job': \"교수\"},\n",
    "      {'name': '이상순', 'job': \"학생\"},\n",
    "      {'name': '박보검', 'job': \"개발자\"}]\n",
    "\n",
    "l2 = [{'name': '신동엽', 'job': \"치과의사\"},\n",
    "      {'name': '이영자', 'job': \"농부\"},\n",
    "      {'name': '정찬우', 'job': \"연예인\"}]\n",
    "         \n",
    "df1 = pd.DataFrame(l1, columns = ['name', 'job'])\n",
    "df2 = pd.DataFrame(l2, columns = ['name', 'job'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1하위로 df2가 병함, 단 , 개별 index가 유지 및 컬럼명 유지로 인한 \n",
    "#불안정한 결과 \n",
    "df3=[df1,df2]\n",
    "df4=pd.concat(df3,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 두개의 DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l1 = [{'name': '이효리', 'job': \"교수\"},\n",
    "      {'name': '이상순', 'job': \"학생\"},\n",
    "      {'name': '박보검', 'job': \"개발자\"}]\n",
    "\n",
    "l2 = [{'name': '신동엽', 'job': \"치과의사\"},\n",
    "      {'name': '이영자', 'job': \"농부\"},\n",
    "      {'name': '정찬우', 'job': \"연예인\"}]\n",
    "         \n",
    "df1 = pd.DataFrame(l1, columns = ['name', 'job'])\n",
    "df2 = pd.DataFrame(l2, columns = ['name', 'job'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat 함수로 병합해 보기 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=[df1,df2]\n",
    "df4=pd.concat(df3, axis=1, ignore_index=True)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#header 부분 즉 컬럼명 추가하기\n",
    "df4.columns=['name','job','name','job']\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
